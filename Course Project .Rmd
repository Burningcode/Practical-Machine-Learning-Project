---
title: "Practical Machine Learning Course Project"
author: "Clay Burns"
date: "July 23, 2015"
output: html_document
---
#Overview
This is a report for the Machine Learning Course offered by John Hopkins on Coursera. This report describes data processing and model building in steps performed on the Data Classification of Body Postures and Movements dataset. More information can be found here, http://groupware.les.inf.puc-rio.br/har

In brief terms the aim is to build a prediction model that can predict the technique of someone lifting weights based on data from a Fitbit. This model is both Train and tested.


#Data Acquisition 
##Loading Data
The training and testing data can be read from these sources.


```{r}
url1 <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url1, destfile="pml-training.csv")
url2 <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url2, destfile="pml-testing.csv")
dataTrain <- read.csv("pml-training.csv", header=TRUE)
dataTest <- read.csv("pml-testing.csv", header=TRUE)
```
The dataTest set will be used to examine accuracy while exploration and analysis are performed on the dataTrain set.

##Data Summmary  
``` {r}
summary(dataTrain$var_accel_forearm)
summary(dataTrain$var_accel_dumbbell)
summary(dataTrain$var_yaw_arm)
```

As can be seen above, many pieces of this data included NA variable in large amounts. For this reason, some data tidying will need to occur before proper model testing..

##Data Cleaning 
```{r}
dataTidy <- dataTrain[,-c(grep("^amplitude|^kurtosis|^skewness|^avg|^cvtd_timestamp|^max|^min|^new_window|^raw_timestamp|^stddev|^var|^user_name|X",names(dataTrain)))]

paste("Complete Cases:")
```

```{r}
table(complete.cases(dataTidy))
```
After some data tidying, we now have only complete cases.

#Packages Preparation 
For the model generation we will need the following packages.


```{r}
library(caret)
library(lattice)
library(gbm)
```
This will let us test Gradient Boosting versus Random Forest during the analysis.
#Data splitting 

Consider the size of the data set we have the ability to split into a secondary set for model validation. The size chosen here was 60% for training, and 40% for a preliminary test.


```{r}
set.seed(1337)
inTrain <- createDataPartition(y=dataTidy$classe,
                               p=0.6,list=FALSE)
dataTidyTrain <- dataTidy[inTrain,]
dataTidyTest <- dataTidy[-inTrain,]
```
#Model Selection
Since we would like to predict on classification random forests and Gradient Boosting will yield strong results. The rf & gbm algorithm should suit the data. 

To handle selection the Kappa metric should provide a non-biased measure of prediction.

Lasting a 10-fold cross validation will reduce the possibility of over fitting. 



```{r}
set.seed(1337)
# k-fold validation - 10-fold validation, use kappa as metric
fitControl <- trainControl(method = "cv",
                           number = 10)
gbmFit <- train(classe~., data=dataTidyTrain, method="gbm", metric="Kappa", trControl=fitControl,verbose=FALSE)
```

```{r}
rfFit <- train(classe~.,data=dataTidyTrain,method="rf", metric="Kappa", trControl=fitControl)
```

#Model Comparison
Below, I create a box plot to examine the Kappa of each model. The Random Forest model produces stronger results, while the Gradient Boosting has a larger spread and seems to require more computational power.


```{r}
rValues <- resamples(list(rf=rfFit,gbm=gbmFit))
summary(rValues)
```

```{r}
bwplot(rValues,metric="Kappa",main="RandomForest (rf) vs Gradient Boosting (gbm)")
```

#Model Validation 
Now with the Random Forest we can proceed to examine how well the Model fits on the dataTidyTest set. I have also included the detail of the selected model.

```{r}
rfFit
```
The caret confusionMatrix function can help validate the selected model. It can be determined that models still performs within its initial kappa bounds with an extremely high accuracy.

```{r}
confusionMatrix(dataTidyTest$classe, predict(rfFit,dataTidyTest))
```

#Final Model Testing 
Final we will use the model to write the results on the test set, as instructed, for a final test.


```{r}
results <- predict(rfFit,newdata=dataTest)
print(as.data.frame(results))
```

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(results)
```